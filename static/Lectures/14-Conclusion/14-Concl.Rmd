---
title: "Multiple Regression & <br><br> Fundamentals of Causal Inference"
subtitle: "13. Conclusion"
author: "Merlin Schaeffer<br> Department of Sociology"
date: "`r Sys.Date()`"
output: 
  xaringan::moon_reader:
    chakra: "../template/remark-latest.min.js"
    css: ["../template/Merlin169.css"]
    lib_dir: libs
    # self_contained: true
    nature:
      highlightLanguage: r
      highlightStyle: zenburn
      highlightLines: true
      countIncrementalSlides: false
      ratio: '16:9'
---
```{r setup, include = FALSE}
library(RefManageR)
library(knitr)
library(ggrepel) # Nicely placed labels in figures.
library(modelr)
library(essentials)
library(tidyverse)
library(equatiomatic) # Regression equations from model objects.
library(estimatr)
library(masteringmetrics)
library(modelsummary)

options(htmltools.preserve.raw = FALSE, tikzDefaultEngine = "xetex",
        htmltools.dir.version = FALSE, servr.interval = 0.5, width = 115, digits = 3)
knitr::opts_chunk$set(
  collapse = TRUE, message = FALSE, fig.retina = 3, error = TRUE,
  warning = FALSE, cache = FALSE, fig.align = 'center',
  comment = "#", strip.white = TRUE, tidy = FALSE)

BibOptions(check.entries = FALSE, 
           bib.style = "authoryear", 
           style = "markdown",
           hyperlink = FALSE,
           no.print.fields = c("doi", "url", "ISSN", "urldate", "language", "note", "isbn", "volume"))
myBib <- ReadBib("./../../../Stats_II.bib", check = FALSE)

xaringanExtra::use_xaringan_extra(c("tile_view", "tachyons"))
xaringanExtra::use_panelset()

load("Result.RData")
```
# Goal of empirical sociology

.font130[.center[.alert[Use data to discover patterns], <br> .alert[and the social mechanisms that bring them about.]]]

```{r, echo = FALSE, out.width='50%', fig.align='center'}
knitr::include_graphics('https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgykJbXZbwIX-nd1oVOyzmEfj09ho8aQ4HBhfMH27t6YeTYSBevfrD2DFTEQSe7e3UwaVnv-fAJAOVpjW2pSGfG2QNrgHfkTmFtRWK4VXl6KmWK6vVlLud0DRU6lFXAqBF7iij420oOTLFh/s1600/photo.JPG')
```

---
# Quizzes

```{r histo, out.width = "65%", fig.height = 3.5, fig.width = 5, echo = FALSE}
plotdata <- result %>% filter(appearances > 7)

ggplot(data = plotdata, aes(x = mcorrect)) +
  geom_histogram(aes(y = after_stat(count / sum(count)))) +
  scale_y_continuous(labels = scales::percent) + 
  geom_vline(xintercept = mean(plotdata$mcorrect)) +
  theme_bw() +
  labs(x = "% of correct answers", y = "% of students")
```

---
# The Null-model

.left-column[
- To the right, we have the Null-model, which simply uses the average as prediction.

- The Null-model explains none of the overall variation of $Y$ (i.e., the red deviations from $\bar{Y}$)
]

.right-column[
```{r nomodel, out.width = "100%", fig.height = 3.5, fig.width = 5, echo = FALSE}
set.seed(08031983)
plotdata <- plotdata %>%
  mutate(appearances = appearances + rnorm(mean = 0, sd = 0.25, n = length(plotdata)))

ggplot(data = plotdata, aes(y = mcorrect, x = appearances)) +
  geom_point(alpha = 1/3, size = 3) +
  geom_hline(yintercept = mean(plotdata$mcorrect)) +
  theme_bw() +
  labs(y = "% of correct answers", x = "Nr. of completed quizzes") +
  geom_linerange(data = plotdata, mapping = aes(ymin = mean(plotdata$mcorrect), ymax = plotdata$mcorrect), color = "#901A1E")
```
]

---
# We studied OLS regression

.left-column[
```{r echo=FALSE}
moderat <- plotdata %>%
  lm(formula = mcorrect ~ appearances, data = .)
```
- OLS estimates the parameters of a specified model, here `r extract_eq(moderat, use_coefs = FALSE)`, by $\text{min}(e^2)$.

- OLS regression can be regarded as a knife that cuts the overall variation in $Y$ into two parts:
  1. .alert2[Blue: Explained by the model.]
  2. .alert[Red: Residual, unexplained by the model.]
]

.right-column[
```{r ols1, out.width = "100%", fig.height = 3.5, fig.width = 5, echo = FALSE}
plotdata <- plotdata %>% 
  add_residuals(model = moderat) %>% 
  add_predictions(model = moderat)

ggplot(data = plotdata, aes(y = mcorrect, x = appearances)) +
  geom_point(alpha = 1/3, size = 3) +
  geom_hline(yintercept = mean(plotdata$mcorrect)) +
  geom_smooth(method = "lm", color = "#005b96") +
  theme_bw() +
  labs(y = "% of correct answers", x = "Nr. of completed quizzes") +
  geom_linerange(data = plotdata,
                 mapping = aes(ymin = pred, ymax = (resid + pred)), color = "#901A1E") +
  geom_linerange(data = plotdata,
                 mapping = aes(ymin = mean(plotdata$mcorrect), ymax = (pred)), color = "#005b96")
```
]

---
# Two Goals

.push-left[
.center[
**1) Describe patterns accurately**

$\rightarrow$ Increase the explained blue variation and<br> decrease the unexplained red part.
]

1. *Dummy coding* for categorical variables.
2. *Multiple OLS* for multiple predicators.
3. *Interaction effects* for conditional associations.
4. *Polynomials & transformations* for non-linear associations.
]

.push-right[
.center[
**2) Identify causal mechanisms**

$\rightarrow$ Use a research design to randomly assign $X$.<br>
(All variation in $X$ is random)
]

1. *Randomized Controlled Trials* (RCT)
2. *Intention to Treat Designs* (ITT, Reduced Form)
3. *Instrument Variable Regression* (Wald)

<br>
.center[
$\rightarrow$ Use OLS to identify random variation in $X$.<br>
(Most variation in $X$ is not random)
]

3. *Instrument Variable Regression* (2SLS)
4. *Control for confounders*
]

---
class: inverse middle center

# Goal 1: Describe patterns accurately

### $\rightarrow$ Increase the explained blue variation and<br> decrease the unexplained red part.

---
# Categorical \ Dummy variables

.push-left[
$$x=
  \begin{cases}
    1, & \text{if condition is met} \\
    0 & \text{otherwise}
  \end{cases}$$

Name                       | Female | Male | ...
---------------------------------|----|----|----
Søren                 | 0  | 1  | 0 
Hannah                 | 1  | 0  | 0
...                 | 1  | 0  | 0
Asger                          | 0  | 1  | 0  
Merlin                          | 0  | 1  | 0
...                          | 0  | 1  | 0
]

.push-right[
```{r echo = FALSE}
plotdata <- plotdata %>%
  mutate(
    gndr = case_when(
      woman > 0.5 ~ "Women",
      TRUE ~ "Men"))
```
```{r}
ols <- lm_robust(mcorrect ~ gndr, data = plotdata) # OLS

# Regression table with nice layout
modelsummary(list("% Correct" = ols), stars = TRUE,
  gof_map = c("nobs", "r.squared"), output = "gt")
```
]

---
# Categorical \ Dummy variables

.push-left[.font90[
```{r eval = FALSE}
library(text) # Large language models from Huggingface.com

# LLM zero-shot encoding 
## 1. Predict gender of first names.
###################################
zeroshot <- text::textZeroShot(
  # List of names.
  sequences = result$name,
  # Possible gender(s) for names.
  candidate_labels = c("woman"),
  # Multiple genders per name?
  multi_label = FALSE,
  # Template for hypothesis for each name.
  hypothesis_template = "A Person with this name is a {}.",
  # The model that is used to predict the gender.
  model = "alexandrainst/scandi-nli-base")
```
]]

.push-right[
```{r dummy, out.width = "100%", fig.height = 4.5, fig.width = 5, echo = FALSE}
ggplot(data = plotdata, aes(y = mcorrect, x = woman)) +
  geom_point(aes(color = woman), alpha = 1/2, size = 3) +
  geom_hline(yintercept = mean(plotdata$mcorrect)) +
  geom_smooth(method = "lm", color = "#005b96") +
  theme_bw() +
  scale_x_continuous(breaks = c(0.08, 0.5, 0.97), 
                     labels = c("0 = Male", "0.5", "1 = Female")) +
  labs(color = "Female",
    y = "% of correct answers", x = "Gender") +
  theme(legend.position="bottom")
```
]

---
# Stats skills = $f(\text{your name})$?

.push-left[
.font90[
```{r eval = FALSE}
# LLM zero-shot encoding 
## 1. Predict gender of first names.
###################################
zeroshot <- text::textZeroShot(
  # The list of first names to be predicted.
  sequences = result$name,
  # The possible genders for the first names.
  candidate_labels = c("Statistics"),
  # Indicates whether multiple genders should be predicted for each first name.
  multi_label = FALSE,
  # The template for the hypothesis that is generated for each first name.
  hypothesis_template = "A Person with this name is great at {}.",
  # The model that is used to predict the gender.
  model = "alexandrainst/scandi-nli-base")
```
]]

.push-right[
```{r quatsch, out.width = "100%", fig.height = 4.5, fig.width = 5, echo = FALSE}
ggplot(data = plotdata, aes(y = mcorrect, x = Statistics)) +
  geom_point(aes(color = Statistics), alpha = 1/2, size = 3) +
  geom_hline(yintercept = mean(plotdata$mcorrect)) +
  geom_smooth(method = "lm", color = "#005b96") +
  theme_bw() +
  labs(color = "Stats skills",
    y = "% of correct answers", x = "LLM-predicted stats skills \n (based on your name)") +
  theme(legend.position="bottom")
```
]

---
# Multiple OLS

.push-right[
<br>

```{r echo = FALSE}
ols2 <- lm_robust(mcorrect ~ gndr + Statistics + appearances, data = plotdata) # OLS

# Regression table with nice layout
modelsummary(list("% Correct" = ols2), stars = TRUE,
             coef_rename = c("gndrWomen" = "Female", 
                             "Statistics" = "Stats skills",
                             "appearances" = "Nr. completed quizzes"),
             gof_map = c("nobs", "r.squared"), output = "gt")
```
]

.push-left[
<br>

$$Y_{i} = \alpha + \beta_{2} X_{1i} + \ldots + \beta_{k} X_{ki} + \epsilon_{i}$$
]

---
# Interaction \ conditional effects

.push-right[
```{r inter, out.width = "100%", fig.height = 4.5, fig.width = 5, echo = FALSE}
ggplot(data = plotdata, aes(y = mcorrect, x = appearances)) +
  geom_point(aes(color = gndr), alpha = 1/2, size = 3) +
  geom_hline(yintercept = mean(plotdata$mcorrect)) +
  geom_smooth(aes(color = gndr, fill = gndr), method = "lm") +
  theme_bw() +
  scale_color_manual(values = c("#901A1E", "#005b96")) +
  scale_fill_manual(values = c("#901A1E", "#005b96")) +
  labs(color = "Gender", fill = "Gender",
       y = "% of correct answers", x = "Nr. of completed quizzes") +
  theme(legend.position="bottom")
```
]


.push-left[
$$Y_{i} = \alpha + \beta_{2} X_{1i} + \beta_{2} X_{2i} + \color{orange}{\beta_{3} X_{1i}*X_{2i}} + \epsilon_{i}$$
```{r echo = FALSE}
ols3 <- lm_robust(mcorrect ~ gndr*appearances, data = plotdata) # OLS

# Regression table with nice layout
modelsummary(list("% Correct" = ols3), stars = TRUE,
             coef_rename = c("gndrWomen" = "Female", 
                             "appearances" = "Nr. completed quizzes"),
             gof_map = c("nobs", "r.squared"), output = "gt")
```
]

---
# Polynomials

.push-left[
$$Y_{i} = \alpha + \beta_{1} X_{1i} + \color{orange}{\beta_{2} X_{1i}^2 + \beta_{3} X_{1i}^3} + \epsilon_{i}$$

```{r echo=FALSE}
mod1 <- plotdata %>%
  lm_robust(formula = mcorrect ~ appearances, data = .)
mod2 <- plotdata %>%
  lm_robust(formula = mcorrect ~ poly(appearances, 3, raw = TRUE), data = .)

# Regression table with nice layout
modelsummary(list("% Correct" = mod1, "% Correct" = mod2), stars = TRUE,
             coef_rename = c("gndrWomen" = "Female", 
                             "appearances" = "Nr. completed quizzes",
                             "poly(appearances, 3, raw = TRUE)1" = "Nr. completed quizzes",
                             "poly(appearances, 3, raw = TRUE)2" = "Nr. completed quizzes^2",
                             "poly(appearances, 3, raw = TRUE)3" = "Nr. completed quizzes^3"),
             gof_map = c("nobs", "r.squared"), output = "gt")
```
]

.push-right[
```{r poly, out.width = "100%", fig.height = 4.5, fig.width = 5, echo = FALSE}
plotdata <- plotdata %>% 
  add_residuals(model = mod2) %>% 
  add_predictions(model = mod2)

ggplot(data = plotdata, aes(y = mcorrect, x = appearances)) +
  geom_point(alpha = 1/2, size = 3) +
  geom_hline(yintercept = mean(plotdata$mcorrect)) +
  geom_smooth(method = "lm", formula = y~poly(x,3), color = "#005b96") +
  theme_bw() +
  labs(color = "Gender", fill = "Gender",
       y = "% of correct answers", x = "Nr. of completed quizzes") +
  theme(legend.position="bottom") +
  geom_linerange(data = plotdata,
                 mapping = aes(ymin = pred, ymax = (resid + pred)), color = "#901A1E") +
  geom_linerange(data = plotdata,
                 mapping = aes(ymin = mean(plotdata$mcorrect), ymax = (pred)), color = "#005b96")
```
]

---
# Transformations

.push-left[
$$Y_{i} = \alpha +  \color{orange}{\beta_{1} \text{log}_{2}(X_{1i})} + \epsilon_{i}$$

```{r echo=FALSE}
modder <- plotdata %>%
  lm_robust(formula = mcorrect ~ I(log2(appearances)), data = .)

# Regression table with nice layout
modelsummary(list("% Correct" = modder), stars = TRUE,
             coef_rename = c("gndrWomen" = "Female", 
                             "appearances" = "Nr. completed quizzes"),
             gof_map = c("nobs", "r.squared"), output = "gt")
```
]

.push-right[
```{r trans, out.width = "100%", fig.height = 4.5, fig.width = 5, echo = FALSE}
plotdata <- plotdata %>% 
  add_residuals(model = modder) %>% 
  add_predictions(model = modder)

ggplot(data = plotdata, aes(y = mcorrect, x = appearances)) +
  geom_point(alpha = 1/2, size = 3) +
  geom_hline(yintercept = mean(plotdata$mcorrect)) +
  geom_smooth(method = "lm", formula = y ~ log2(x), color = "#005b96") +
  theme_bw() +
  labs(color = "Gender", fill = "Gender",
       y = "% of correct answers", x = "Nr. of completed quizzes") +
  theme(legend.position="bottom") +
  geom_linerange(data = plotdata,
                 mapping = aes(ymin = pred, ymax = (resid + pred)), color = "#901A1E") +
  geom_linerange(data = plotdata,
                 mapping = aes(ymin = mean(plotdata$mcorrect), ymax = (pred)), color = "#005b96")
```
]

---
# You can combine these techniques

.push-left[
$$Y_{i} = \alpha + \beta_{1} X_{1i} + \beta_{2} X_{2i} + \color{orange}{\beta_{2} X_{1i}^2 + \beta_{3} X_{1i} * X_{2i} + \beta_{4} X_{1i}^2 * X_{2i}} + \epsilon_{i}$$

```{r echo=FALSE}
mod <- plotdata %>%
  lm_robust(formula = mcorrect ~ gndr*poly(appearances, 2, raw = TRUE), data = .)

# Regression table with nice layout
modelsummary(list("% Correct" = mod), stars = TRUE,
             coef_rename = c("gndrWomen" = "Female", 
                             "poly(appearances, 2, raw = TRUE)1" = "Nr. completed quizzes",
                             "poly(appearances, 2, raw = TRUE)2" = "Nr. completed quizzes^2"),
             gof_map = c("nobs", "r.squared"), output = "gt")
```
]

.push-right[
```{r combi, out.width = "100%", fig.height = 4.5, fig.width = 5, echo = FALSE}
ggplot(data = plotdata, aes(y = mcorrect, x = appearances)) +
    geom_point(aes(color = gndr), alpha = 1/2, size = 3) +
  geom_hline(yintercept = mean(plotdata$mcorrect)) +
  geom_smooth(aes(color = gndr, fill = gndr), method = "lm", formula = y ~ poly(x,2)) +
  theme_bw() +
  scale_color_manual(values = c("#901A1E", "#005b96")) +
  scale_fill_manual(values = c("#901A1E", "#005b96")) +
  labs(color = "Gender", fill = "Gender",
       y = "% of correct answers", x = "Nr. of completed quizzes") +
  theme(legend.position="bottom")
```
]
---
class: inverse middle center

# Goal 2: Identify causal mechanisms

---
# Selection \ omitted variable bias

.push-left[
$$\begin{equation} \begin{split}
\underbrace{Avg_{n}[Y_{1i}|D_{i} = 1] - Avg_{n}[Y_{0i}|D_{i} = 0]}_{\text{Difference in observed group means}} = \underbrace{Avg_{n}[Y_{1i}|D_{i} = 1] \color{gray}{(-  Avg_{n}[Y_{0i}|D_{i} = 1]}}_{\text{Average causal effect } among \text{ } the \text{ } treated} \color{gray}{+} \underbrace{\color{gray}{Avg_{n}[Y_{0i}|D_{i} = 1])} -  Avg_{n}[Y_{0i}|D_{i} = 0]}_{\text{Selection bias}}.
\end{split} \end{equation}$$
<br>
<br>
<br>

$$\tilde{\beta}_{Y \leftarrow X} = \beta_{Y \leftarrow X} + \underbrace{(\beta_{Y \leftarrow C} \times \beta_{C \leftarrow X})}_{\text{Omitted Variable Bias}}$$
]
<br>
<br>
<br>
<br>
<br>

.push-right[
```{tikz, DAG1,  echo = FALSE, out.width='60%'}
\usetikzlibrary{shapes,decorations,arrows,calc,arrows.meta,fit,positioning}
\tikzset{
    -Latex,auto,node distance =1 cm and 1 cm,semithick,
    state/.style ={ellipse, draw, minimum width = 0.7 cm},
    point/.style = {circle, draw, inner sep=0.04cm,fill,node contents={}},
    bidirected/.style={Latex-Latex,dashed},
    el/.style = {inner sep=2pt, align=left, sloped}
}

\begin{tikzpicture}
\sffamily
    \node[state] (1) at (0,0) {$C$};
    \node[state] (2) [below = of 1] {$X$};
    \node[state] (3) [right = of 2] {$Y$};

    \path (1) edge  (2);
    \path[bidirected] (2) edge[red, bend right=50] (3);
    \path (1) edge (3);
\end{tikzpicture}
```
]

---
class: inverse middle center

## $\rightarrow$ Use a research design to randomly assign $X$.
### (All variation in $X$ is random)

---
# RCT .font60[& natural RCT]

.left-column[
- We $\color{red}I$intervene & $I$ perfectly determines who gets $X$ and who does not (i.e., $|r| = 1$).

- If the $I$ntervention is categorical, a simple bivariate model suffices: $Y = \alpha + \color{red}{\beta} I_i + \epsilon_i$

- If the $I$ntervention is continuous, one can test for a non-linear causal effect, for example: $Y = \alpha + \color{red}{\beta_1} I_i + \color{red}{\beta_2} I_i^2 + \epsilon_i$

- We can use interaction effects to investigate whether $X$ affects subpopulations differently: $Y = \alpha + \color{red}{\beta_1} I_i + \beta X_i + \color{red}{\beta_2} I_i*X_i + \epsilon_i$


]
.push-right[
```{tikz, DAG2,  echo = FALSE, out.width='100%'}
\usetikzlibrary{shapes,decorations,arrows,calc,arrows.meta,fit,positioning,quotes}
\tikzset{
  -Latex,auto,node distance =1 cm and 1 cm,semithick,
  state/.style ={ellipse, draw, minimum width = 0.7 cm},
  point/.style = {circle, draw, inner sep=0.04cm,fill,node contents={}},
  bidirected/.style={Latex-Latex, dashed},
  el/.style = {inner sep=2pt, align=left, sloped}
}

\begin{tikzpicture}
\sffamily
    \node[state] (1) [red] at (0,0) {$I$};
    \node[state] (2) [right = of 1] {$X$};
    \node[state] (3) [above = of 2] {$C$};
    \node[state] (4) [right = of 2] {$Y$};

  \path (1) [red] edge ["$|r| = 1$"] (2);
  \path (2) edge (4);
  \path (3) edge [dashed] (4);
  \path (3) edge [dashed] (2);
  \end{tikzpicture}
```
]

---
# ITT

.left-column[
- We $\color{red}I$ntervene, but $I$ does not perfectly determine who gets $X$ and who does not (i.e., $|r| < 1$).

- We can estimate ITT just like RCT effects, but it gives us causal effect of $I$ not of $X$. 

- To get causal effect of X (for compliers): $y = \alpha + \lambda X_i + \epsilon_i; \text{with } \lambda = \frac{\text{ITT}}{r}$


]
.push-right[
```{tikz, DAG3,  echo = FALSE, out.width='50%'}
\usetikzlibrary{shapes,decorations,arrows,calc,arrows.meta,fit,positioning,quotes}
\tikzset{
  -Latex,auto,node distance =1 cm and 1 cm,semithick,
  state/.style ={ellipse, draw, minimum width = 0.7 cm},
  point/.style = {circle, draw, inner sep=0.04cm,fill,node contents={}},
  bidirected/.style={Latex-Latex, dashed},
  el/.style = {inner sep=2pt, align=left, sloped}
}

\begin{tikzpicture}
\sffamily
    \node[state] (1) [red] at (0,0) {$I$};
    \node[state] (2) [right = of 1] {$Y$};

  \path (1) [red] edge ["ITT"] (2);
  \end{tikzpicture}
```

```{tikz, DAG4,  echo = FALSE, out.width='100%'}
\usetikzlibrary{shapes,decorations,arrows,calc,arrows.meta,fit,positioning,quotes}
\tikzset{
  -Latex,auto,node distance =1 cm and 1 cm,semithick,
  state/.style ={ellipse, draw, minimum width = 0.7 cm},
  point/.style = {circle, draw, inner sep=0.04cm,fill,node contents={}},
  bidirected/.style={Latex-Latex, dashed},
  el/.style = {inner sep=2pt, align=left, sloped}
}

\begin{tikzpicture}
\sffamily
    \node[state] (1) [red] at (0,0) {$I$};
    \node[state] (2) [right = of 1] {$X$};
    \node[state] (3) [above = of 2] {$C$};
    \node[state] (4) [right = of 2] {$Y$};

  \path (1) [red] edge ["$|r| < 1$"] (2);
  \path (2) edge (4);
  \path (3) edge [dashed] (4);
  \path (3) edge [dashed] (2);
  \end{tikzpicture}
```
]
---
class: inverse middle center

## $\rightarrow$ Use OLS to identify random variation in $X$.<br>
### (Most variation in $X$ is *not* random)

---
# $I$, $C$, and $M$

.push-left[
- If $X$ was random and sociologically relevant, you have an natural experiment. The you can just proceed like with a RCT.

- In a "first step", $X$ can be the outcome of $I$ or $C$. Remember, the .alert2[blue part is explained] by $I | C$, the .alert[red part is unexplained] by it.

- If you find a random $I$ that causes $X$, you use the blue variation of $X$ in a 2SLS-IV. We identify the blue variation by predicting $\hat{X}$.

- If you have observed a counfounder $C$, you use the red variation of $X$ that is unconfounded by it. You can do that by adding $C$ to a multiple regression.

- If you have a mediator $M$, you add it in a second step and see how much $X$ is reduced (aka explained \ mediated) by it. 
]
.push-right[
```{r ref.label = "ols1", out.width = "80%", fig.height = 3.5, fig.width = 5, echo = FALSE}
```

```{tikz, DAG5,  echo = FALSE, out.width='60%'}
\usetikzlibrary{shapes,decorations,arrows,calc,arrows.meta,fit,positioning,quotes}
\tikzset{
  -Latex,auto,node distance =1 cm and 1 cm,semithick,
  state/.style ={ellipse, draw, minimum width = 0.7 cm},
  point/.style = {circle, draw, inner sep=0.04cm,fill,node contents={}},
  bidirected/.style={Latex-Latex, dashed},
  el/.style = {inner sep=2pt, align=left, sloped}
}

\begin{tikzpicture}
\sffamily
    \node[state] (1) [red] at (0,0) {$I$};
    \node[state] (2) [right = of 1] {$X$};
    \node[state] (3) [above = of 2] {$C$};
    \node[state] (4) [right = of 2] {$M$};
    \node[state] (5) [right = of 4] {$Y$};

  \path (1) [red] edge (2);
  \path (2) edge (4);
  \path (4) edge (5);
  \path (3) edge [dashed] (5);
  \path (3) edge [dashed] (2);
  \end{tikzpicture}
```
]

---
# RDD

.left-column[
- We estimate the effect of strict rules that define thresholds on otherwise continuous variables.

- We use regression to use all available cases, but compare predictions of out models above and below the threshold exactly at the threshold.
]
.right-column[
```{r RDD6, out.width='100%', fig.height = 5, fig.width = 8, echo = FALSE}
# Get the Minimum legal drinking age data!
data("mlda", package = "masteringmetrics")
mlda <- mlda %>% drop_na() # Drop missings and print forst 10 rows of the data

mlda <- mlda %>% mutate(
  twentyone = case_when( 
    agecell >= 21 ~ "Yes",
    TRUE ~ "No"),
  # Define those who are allowed to drink
  close = case_when( 
    agecell >= 20.7 & agecell < 21 ~ "No-close",
    agecell >= 21 & agecell < 21.3 ~ "Yes-close",
    agecell >= 21 ~ "Yes",
    TRUE ~ "No"))

# 1. Fit the underlying linear models manually
# (We assume your dataframe is named 'mlda')
model_left  <- lm(all ~ agecell, data = subset(mlda, agecell < 21))
model_right <- lm(all ~ agecell, data = subset(mlda, agecell >= 21))

# 2. Define helper functions to predict Y for any X
pred_left  <- function(x) predict(model_left, newdata = data.frame(agecell = x))
pred_right <- function(x) predict(model_right, newdata = data.frame(agecell = x))

# 3. Get the range of the x-axis to know where lines should start/end
min_x <- min(mlda$agecell)
max_x <- max(mlda$agecell)

# 4. Plot
ggplot(data = mlda, aes(y = all, x = agecell, color = close)) +
  geom_point() +
  geom_vline(xintercept = 21, color = "#e41a1c") +
  geom_smooth(aes(color = twentyone), method = "lm") +
    geom_segment(aes(x = min_x, xend = 21, 
                   y = pred_left(min_x), yend = pred_left(21)), 
               color = "#9970ab", size = 1, inherit.aes = FALSE) +
    geom_segment(aes(x = 21, xend = max_x, 
                   y = pred_left(21), yend = pred_left(max_x)), 
               color = "#9970ab", linetype = "dashed", size = 1, inherit.aes = FALSE) +
    # Right Model (Green): Solid after 21, Dashed before 21
  geom_segment(aes(x = 21, xend = max_x, 
                   y = pred_right(21), yend = pred_right(max_x)), 
               color = "#a6dba0", size = 1, inherit.aes = FALSE) +
  geom_segment(aes(x = min_x, xend = 21, 
                   y = pred_right(min_x), yend = pred_right(21)), 
               color = "#a6dba0", linetype = "dashed", size = 1, inherit.aes = FALSE) +
  theme_minimal() + 
  scale_color_manual(values = c("#9970ab", "#c51b7d", "#a6dba0", "#2166ac")) +
  labs(y = "Nr of deaths per 100.000 US Americans \n aged 20-22 (1997-2003)",
       x = "Age in months") +
  guides(color = "none")
```
]

---
class: inverse middle center

# Spørgsmål?
