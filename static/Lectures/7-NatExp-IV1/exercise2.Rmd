---
title: "Exercise 2 (20 minutes)"
subtitle: "When you're done, assist some of the others ..."
output: webexercises::webexercises_default
---

```{r setup, include = FALSE}
options(htmltools.dir.version = FALSE, servr.interval = 0.5, width = 115, digits = 2)
knitr::opts_chunk$set(
  collapse = TRUE, message = FALSE, 
  warning = FALSE, cache = FALSE,
  comment = "#", strip.white = TRUE)

library(webexercises)
library(essentials)
```

```{r}
pacman::p_load(
  tidyverse, # Data manipulation,
  ggplot2, # beautiful figures,
  estimatr, # Regression for weighted data,
  modelr, # Turn results of lm() into a tibble,
  modelsummary, # for balance and regression tables
  ivreg, # IV 2SLS,
  masteringmetrics) # Data and examples from Mastering Metrics

# Load the data from the Minneapolis Domestic Violence Experiment
data("mdve", package = "masteringmetrics")
```

1. The variable `T_RANDOM` contains the information about which strategy the police offers where supposed to use for the respective domestic violence emergency call: 1 indicates "Arrest", 2 "Advise to stop", 3 "Suspect Told to Leave", and 4 "Other". By contrast, the variable `T_FINAL` contains the information about what the police officers actually did when arriving at the scene. Recode the two variables into a respective factor variable, which combines 2 & 3 into a category "Coddle" versus 1 "Arrested", and 4 as `NA`. Make "Arrested" the reference.

How many police officers complied to the strategy that was *randomly* assigned to them? `r fitb(268, width = "3")`

`r hide("R solution -> dont' peak to early ;) !")`
```{r}
mdve <- mdve %>%
  # Recode into factor variables with two categories
  mutate( 
    T_RANDOM = case_when(
      T_RANDOM == 2 | T_RANDOM == 3 ~ "Coddle!",
      T_RANDOM == 1 ~ "Arrest!",
      TRUE ~ as.character(NA)) %>% fct_relevel("Arrest!"),
    T_FINAL = case_when(
      T_FINAL == 2 | T_FINAL == 3 ~ "Coddled",
      T_FINAL == 1 ~ "Arrested",
      TRUE ~ as.character(NA)) %>% fct_relevel("Arrested"))

# Make frequency table
mdve %>%
  select(T_RANDOM, T_FINAL) %>%
  table()

# Compliers:
91 + 177
```
`r unhide()`

2. The variable `S_RACE` indicates the subject's (i.e. the person accused of domestic violence) race. The categories used by the police back in '81 where: 1 "White", 2 "Black", 3 "Indian", 4 "Asian", 5 "Hispanic", as well as sevel small other categories. Did the randomization work, or where certain groups more likely to face a police officers who got advised to arrest/coddle them? `r mcq(c("No, there is strong imbalance in the absolute frequencies", "Yes, the proprotions of the different groups are pretty similar across the two strategies", answer = "For 'Indians' the balance looks pretty off"))`.

`r hide("R solution -> dont' peak to early ;) !")`
```{r}
mdve <- mdve %>%
  mutate( # Recode race variable
    S_RACE = case_when(
      S_RACE == 1 ~ "White",
      S_RACE == 2 ~ "Black",
      S_RACE == 3 ~ "Indian",
      S_RACE == 4 ~ "Asian",
      S_RACE == 5 ~ "Hispanic",
      TRUE ~ "Other"))

mdve %>%
  # Select variables for which I want my balance test,
  select(T_RANDOM, S_RACE) %>%
  datasummary_balance( # Make a balance table,
    formula = ~ T_RANDOM, # by police strategy
    data = . ,
    title = "Subject's race by assigned policing strategy") 
```
`r unhide()`

3. How about if we look at the strategy that the police officers actually used? `r mcq(c("There is still strong imbalance in the absolute frequencies", answer = "Interestingly, now the proprotions of the different groups are pretty similar across the two strategies", "Particularly white subjects got the more lenient treatment than randomly assigned."))`.

`r hide("R solution -> dont' peak to early ;) !")`
```{r}
mdve %>%
  # Select variables for which I want my balance test,
  select(T_FINAL, S_RACE) %>%
  datasummary_balance( # Make a balance table,
    formula = ~ T_FINAL, # by police strategy
    data = . ,
    title = "Subject's race by assigned policing strategy") 
```
`r unhide()`

```{r first_stage, include = FALSE}
mdve <- mdve %>%
  mutate(
    T_FINAL_01 = case_when(
      T_FINAL == "Arrested" ~ 0,
      T_FINAL == "Coddled" ~ 1))

ols <- lm_robust(T_FINAL_01 ~ T_RANDOM, data = mdve)

modelsummary(list("Repeat violence" = ols), stars = TRUE,
             gof_map = c("nobs", "r.squared"))
```

```{r include = FALSE}
coef <- coef(ols, digits = 3)["T_RANDOMCoddle!"] %>% as.scalar()
```
4. How much higher was the probability that police officers would "coddle" a subject rather than arrest them, if they were randomly told to do so? `r fitb(coef, width = "3")` (complete decimals). In IV language, this is called the `r mcq(c("Reduced form", answer = "First stage", "LATE estimate"))`.
`r hide("R solution -> dont' peak to early ;) !")` 
```{r ref.label = "first_stage"}
```
`r unhide()`

5. According to Sherman and Berk (1984, see also Angrist and Pischke's "Mastering Metrics"), the probability that a subject would repeat to assault their partner at home was **0.114** higher when the police officers were *randomly* told to cuddle, as compared to when they were told to arrest (regardless of what they actually did at the scene). In IV language, this is called the `r mcq(c(answer = "Reduced form", "First stage", "LATE estimate"))`.

6. Based on the above information, what is the IV estimate of the local average causal effect of coddling subjects who are accused of domestic violence on the probability that they repeat to assault their partner? It is: `r fitb(0.14, width = "4")` (two decimals).
`r hide("R solution -> dont' peak to early ;) !")`
```{r}
# The IV estimate is:
0.114  / 0.79
```
`r unhide()`